% !TEX root = kocher-topk-indexing.tex

Data with hierarchical structure are naturally represented as trees. A tree stores data values in node labels and encodes the relation between the values in the structure (e.g., text values and element nesting in XML). We consider applications that, given an example tree (the query), are interested in subtrees of a large document tree that are similar to the query. An example is the abstract syntax tree of a large software project~\cite{simian-2019, falleri-ase-2014}: In order to avoid code duplication or detect code moves, software engineers are interested in finding all code fragments (i.e., subtrees of the abstract syntax tree) that are similar to a given example fragment. In RNA secondary structures (which are represented as ordered, labeled trees~\cite{herrbach-tcs-2010, akutsu-ieice-2010}), biologists search for similar foldings of RNA subsequences. To automatically extract product information from the web, the similarity of substructures in web pages are leveraged~\cite{vidal-sigir-2006}. Production engineers retrieve components with similar building plans from bills of materials, which form trees that may consists of millions of nodes~\cite{finis-sigmod-2013,kashkoush-cirp-2013}.

We study \emph{\tssqs{}}: given a large document tree $T$ and a (small) query tree $Q$, find the $k$ most similar subtrees in $T$ w.r.t.\ $Q$. Two trees are similar if their \emph{edit distance}~\cite{zhang-siam-1989}, a common tree similarity measure, is small. The edit distance between two ordered labeled trees is defined as the minimum number of node edit operations (insertion, deletion, rename) that transform one tree into the other.

Previous solutions for \tssqs{} fall into two categories: index-based and index-free algorithms. \tasmpostorder{}~\cite{augsten-icde-2010} is the fastest index-free algorithm and runs in small memory. Unfortunately, \tasmpostorder{} must scan the entire document to answer a top-$k$ query, which is slow.  \structuresearch{}~\cite{cohen-sigmod-2013} addresses this issue and leverages a precomputed index to retrieve candidate subtrees. The candidates must be verified using the edit distance.

\structuresearch{} runs faster than \tasmpostorder{} but suffers from the following issues: (1) The index size is quadratic in the  document size $n$ for deep trees; note that the document is the database over which we answer the top-$k$ query. (2) Despite the index, \structuresearch{} must retrieve and verify many subtrees, which leads to high runtimes also for small values of $k$. (3) While \structuresearch{} can be generalized to generic tree data, the solution is tailored to XML documents, which have many repeating labels in the inner nodes (element tags) and infrequent labels in the leaves (text values). Further, XML trees are typically flat. Flat trees are in favor of \structuresearch{} since the index grows larger for deep trees. (4) The index is not updatable.

Our solution is based on the idea of a \emph{candidate score}. The candidate score ranks all subtrees of a document. The score is high if the query and the subtree share many labels. Intuitively, subtrees with a high score are more likely to be close to the query in terms of edit distance. By processing subtrees in candidate score order, we (a) find good candidates quickly and (b) can stop early when the ranking is good enough, i.e., all remaining subtrees cannot improve the ranking. Stopping early is possible since the candidate score implies a lower bound on the edit distance. The candidate score is very effective. In many settings, we verify orders of magnitude fewer candidate subtrees than \structuresearch{}; in some settings we only verify $k$ candidates, which is optimal.

The challenge is to efficiently generate candidates in score order. The query is not known upfront, thus the order must be established at query time and cannot be precomputed. It is clearly not feasible to enumerate all subtrees and sort them by their score. We introduce a new technique that is based on an inverted list index over the document node labels. The inverted list of a label stores all subtrees that contain that label. We split the lists into partitions of subtrees with the same size and show how to leverage the list partitions to processes the subtrees in score order. The partitions are accessed in the order of the best candidate score that may be found in that partition. Only relevant partitions need to be accessed, e.g., there is only a single partition that may contain subtrees of the highest score.

The catch is that the label inverted list index is quadratic in the document size $n$ for tress with depth $\BigO(n)$; for such trees, also the index of the state-of-the-art algorithm, Structure\-Search, is quadratic. We propose a new algorithm, \shincone{}, which uses an incrementally updatable, linear-space index structure to build the relevant partitions of the inverted lists on the fly at query time. \shincone{} verifies the subtrees in non-decreasing candidate score order. We show how to generate partitions efficiently such that the performance penalty of generating the partitions on the fly is small.

Summarizing, our contributions  are the following.

\begin{itemize}
  \item We propose \shincone{}, a new, index-based algorithm for the top-$k$ subtree similarity problem. \shincone{} verifies subtrees in decreasing candidate score order, i.e., more promising subtrees are processed first. \shincone{} does not require any parameters and is not tailored to a specific data type.
  \item The state-of-the-art algorithm uses a quadratic-size index. We propose the first linear-space index for \tssqs{}. Our index groups subtrees into partitions. All subtrees in a partition have the same guarantee w.r.t.\ to the candidate score such that we find promising subtrees efficiently.
  \item We propose an extension of \shincone{} that supports incremental index updates. Previous work must recompute the index from scratch when the document tree is updated.
  \item We empirically evaluate our solution on large synthetic and real-world data sets. Our technique clearly outperforms the state of the art  w.r.t.\  memory usage, indexing time, number of verified candidates, and query runtime, often by orders of magnitude.
\end{itemize}

The remaining paper is organized as follows. \secref{background-notations} provides background material and introduces the problem statement. \secref{principal-idea} discusses the candidate scores. In Sections~\ref{sec:baseline}-\ref{sec:a-memory-efficient-approach} we present our index structures and algorithms. \secref{efficient-index-updates} describes how to make our index incrementally updatable.
%
We discuss related work in \secref{related-work}. Before we conclude in \secref{conclusion-future-work}, we provide empirical evidence of the scalability and efficiency of our solution in \secref{empirical-evaluation}.
%
Appendix~\ref{sec:appendix} provides proofs to all lemmata and theorems, and the pseudo codes for all algorithms described in Sections~\ref{sec:baseline}-\ref{sec:a-memory-efficient-approach}.
